\documentclass[10pt]{article}
\usepackage{amsmath,amssymb,amsthm}
\usepackage{graphicx}
\usepackage[margin=1in]{geometry}
\usepackage{fancyhdr}
\setlength{\parindent}{0pt}
\setlength{\parskip}{5pt plus 1pt}
\setlength{\headheight}{13.6pt}

\begin{document}
\hrulefill
\begin{itemize}
	\item Nikhil Kamthe
	\item 861245635
	\item 10/20/2016
	\item CS 229
	\item PS 3
\end{itemize}
\hrulefill

\textbf{Solution:} The loss function with regularization for a linear SVM can be written as
\begin{align*}
L &= C \sum_{i}^{m} [1-y_{i}f(x_{i})]_{+} + \frac{1}{2} w^Tw && \text{where }f(x_{i}) = w^T x_{i} + b
\end{align*}
In order to find the general gradient descent learning rules for linear SVM, we need to find the iterative update in w and b. We can use the following equations to find the iterative updates in w and b.
\begin{align*}
w_{new} &= w_{old} - \eta*\frac{dL}{dw} && \text{where $\eta=$ step size}\\
b_{new} &= b_{old} - \eta*\frac{dL}{db}
\end{align*}
\hrulefill

\textbf{IMPORTANT: Let me introduce following notation to make our life easier}
\begin{align*}
[\phi(x_{i})]_{svm} &= \phi(x_{i}) && \text{ when }y_{i}f(x_{i})<1\\
[\phi(x_{i})]_{svm} &= 0 && \text{ when }y_{i}f(x_{i})\ge 1
\end{align*}

\hrulefill

Lets compute $\frac{dL}{dw}$ and $\frac{dL}{db}$ in order to derive the update rules.
\begin{align*}
\frac{dL}{dw} &= C \sum_{i}^{m} [-y_{i}x_{i}]_{svm} + w && \\
\frac{dL}{db} &= C \sum_{i}^{m} [-y_{i}]_{svm}
\end{align*}
Therefore  we can write the general gradient descent update rules for linear SVM as follows.
\begin{align*}
w_{new} &= w_{old} - \eta*(C \sum_{i}^{m} [-y_{i}x_{i}]_{svm} + w_{old})\\
b_{new} &= b_{old} - \eta*(C \sum_{i}^{m} [-y_{i}]_{svm})
\end{align*}
Stochastic gradient descent update rules for linear SVM can be derived by evaluating general gradient descent update rules at a single data point $k$.
\begin{align*}
w_{new} &= w_{old} - \eta*(C [-y_{k}x_{k}]_{svm} + w_{old})\\
b_{new} &= b_{old} - \eta*(C [-y_{k}]_{svm})
\end{align*}
From the update rule we can see that the Perceptron penalizes incorrectly classified examples whereas SVM penalizes incorrectly classified examples and correctly classified examples that lie within the margin. Also, it can be computationally expensive to reach the SVM solution by gradient descent due to quadratic computations and the regularization term. If the training set is not separable perceptron fails while svm finds the minimum cost separation.

\hrulefill
\end{document}

function partc()
% Nikhil Kamthe
% 861245635
% 11/15/2016
% CS 229
% PS 6
%
% This method uses train and test datasets for spam data and uses bagging
% and boosting to predict the output. It then computes the error rate for
% different combinations to generate plots for each of these combinations.

tic;
figure(1);
clf;
figure(2);
clf
trainData = load('spamtrain.ascii','-ascii');
testData = load('spamtest.ascii','-ascii');
numberOfTreesArray = floor(logspace(0,3,10));
depths = 1:3;
for depth = depths
    index = 1;
    baggingTrainErrorArray = zeros(1,length(numberOfTreesArray));
    baggingTestErrorArray = zeros(1,length(numberOfTreesArray));
    boostingTrainErrorArray = zeros(1,length(numberOfTreesArray));
    boostingTestErrorArray = zeros(1,length(numberOfTreesArray));
    [treesBagging] = bagging(trainData,depth,numberOfTreesArray(end));
    [treesBoosting,w] = boosting(trainData,depth,numberOfTreesArray(end));
    for numberOfTrees = numberOfTreesArray
        x_train = trainData(:,1:57);
        y_train = trainData(:,58);
        y_pred = predictBagging(x_train,treesBagging,numberOfTrees);        
        mismatches = find(sign(y_train)~=sign(y_pred));
        baggingTrainErrorArray(index) = (length(mismatches)/length(y_train))*100;
        y_pred = predictBoosting(x_train,treesBoosting,w,numberOfTrees);
        mismatches = find(sign(y_train)~=sign(y_pred));
        boostingTrainErrorArray(index) = (length(mismatches)/length(y_train))*100;
        x_test = testData(:,1:57);
        y_test = testData(:,58);
        y_pred = predictBagging(x_test,treesBagging,numberOfTrees);
        mismatches = find(sign(y_test)~=sign(y_pred));
        baggingTestErrorArray(index) = (length(mismatches)/length(y_test))*100;
        y_pred = predictBoosting(x_test,treesBoosting,w,numberOfTrees);
        mismatches = find(sign(y_test)~=sign(y_pred));
        boostingTestErrorArray(index) = (length(mismatches)/length(y_test))*100;
        index = index + 1;
    end
    figure(1);
    semilogx(numberOfTreesArray,baggingTrainErrorArray,'--','LineWidth',depth);
    hold on;
    semilogx(numberOfTreesArray,baggingTestErrorArray,'-','LineWidth',depth);
    hold on;
    figure(2);
    semilogx(numberOfTreesArray,boostingTrainErrorArray,'--','LineWidth',depth);
    hold on;
    semilogx(numberOfTreesArray,boostingTestErrorArray,'-','LineWidth',depth);
    hold on;
end
figure(1);
xlabel('number of trees');
ylabel('error rate');
title('Bagging');
legend('training data with depth 1','testing data with depth 1','training data with depth 2','testing data with depth 2','training data with depth 3','testing data with depth 3');
hold off;
figure(2);
xlabel('number of trees');
ylabel('error rate');
title('Boosting');
legend('training data with depth 1','testing data with depth 1','training data with depth 2','testing data with depth 2','training data with depth 3','testing data with depth 3');
hold off;
toc;
end

function y = predictBagging(x,trees,numberOfTrees)
% This method uses the trees generated by the bagging function to
% predict the output for input data. It uses numberOfTrees param to use
% only a part of trees to predict the output.

y = zeros(length(x),1);
for i = 1:numberOfTrees
    y = y + dt(x,trees{i});
end
y = y/numberOfTrees;
y(y>=0) = 1;
y(y<0) = -1;
end

function y = predictBoosting(x,trees,w,numberOfTrees)
% This method uses the trees generated and the corresponding weights
% by the boosting function to predict the output for input data. It uses 
% numberOfTrees param to use only a part of trees to predict the output.

y = zeros(length(x),1);
for i = 1:numberOfTrees
    y = y + w(i)*dt(x,trees{i});
end
y(y>=0) = 1;
y(y<0) = -1;
end